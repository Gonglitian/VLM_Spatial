#!/usr/bin/env python3
"""
ç®€å•çš„æ¨¡å‹åŠ è½½æµ‹è¯•è„šæœ¬
"""
import torch
print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")

try:
    from transformers import AutoModel, AutoTokenizer
    print("âœ… Transformerså¯¼å…¥æˆåŠŸ")
    
    # æµ‹è¯•dtypeæ˜ å°„
    DTYPE_MAP = {
        "fp16": torch.float16,
        "float16": torch.float16,
        "bf16": torch.bfloat16,
        "bfloat16": torch.bfloat16,
        "fp32": torch.float32,
        "float32": torch.float32,
    }
    
    dtype = "fp16"
    selected_torch_dtype = DTYPE_MAP.get(dtype.lower())
    print(f"âœ… dtypeæ˜ å°„æµ‹è¯•é€šè¿‡: {dtype} -> {selected_torch_dtype}")
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    base_model = "unsloth/Qwen2.5-VL-3B-Instruct-bnb-4bit"
    print(f"ğŸ”— å°è¯•åŠ è½½æ¨¡å‹: {base_model}")
    
    model = AutoModel.from_pretrained(
        base_model,
        torch_dtype=selected_torch_dtype,
        trust_remote_code=True,
    )
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
    
    # æµ‹è¯•tokenizer
    tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)
    print("âœ… TokenizeråŠ è½½æˆåŠŸ!")
    
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc() 